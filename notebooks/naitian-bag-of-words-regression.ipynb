{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(x):\n",
    "    tag = r\"([\\s\\(\\)\\[\\],\\/-]*\\b((\\d{1,2})[\\s\\(\\)\\[\\],\\/-]*([mf]|female|male))\\b[\\s\\(\\)\\[\\],\\/-]*|\\b[\\s\\(\\)\\[\\],\\/-]*(([mf]|female|male)[\\s\\(\\)\\[\\],\\/-]*(\\d{1,2}))\\b)\"\n",
    "    age = r\"\\d{1,2}\"\n",
    "    gender = r\"(\\b|\\d)([mMfF])\"\n",
    "    match = re.sub(tag, '', x, flags=re.I)\n",
    "    match = emoji.get_emoji_regexp().sub(r'', match)\n",
    "    match = match.translate(str.maketrans('', '', string.punctuation))\n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27454, 6314)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/posts.csv\", index_col=\"id\")\n",
    "ratings = df[[\"title\", \"average_rating\"]].dropna(subset=[\"average_rating\"])\n",
    "\n",
    "X = ratings.title\n",
    "X = X.apply(clean_title)\n",
    "y = ((ratings.average_rating - ratings.average_rating.mean()) / ratings.average_rating.std())\n",
    "y = y > 0\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=5, ngram_range=(3, 4))\n",
    "X = vectorizer.fit_transform(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22176161837916128\n",
      "most negative\n",
      "('of what others', -2.9494446584391345)\n",
      "('not having much luck', -2.3051935231436667)\n",
      "('open to suggestions on', -2.0460379743827244)\n",
      "('lost some weight recently', -1.9452607893586504)\n",
      "('would love to get', -1.8634962680878104)\n",
      "('should do to improve', -1.8150424535037728)\n",
      "('lose weight and', -1.6980477548008965)\n",
      "('to look my best', -1.6857245392193496)\n",
      "('for ways to improve', -1.6805423646361892)\n",
      "('anything like this before', -1.6731685937545036)\n",
      "most positive\n",
      "('been going to the', 2.252834387973641)\n",
      "('change up my hair', 2.0432869294169578)\n",
      "('curious of what others', 1.9828167777791539)\n",
      "('idea what people', 1.9644397127177198)\n",
      "('of what others think', 1.9642896776969638)\n",
      "('really know where stand', 1.9420387050656225)\n",
      "('on what people', 1.8040222175072504)\n",
      "('me what you got', 1.7811485414478139)\n",
      "('im wondering if its', 1.7791824609903149)\n",
      "('be honest can handle', 1.751504900500844)\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X, y)\n",
    "print(reg.score(X, y))\n",
    "print(\"most negative\")\n",
    "print(\"\\n\".join([str((vectorizer.get_feature_names()[i], reg.coef_[i])) for i in reg.coef_.argsort()[:10]]))\n",
    "print(\"most positive\")\n",
    "print(\"\\n\".join([str((vectorizer.get_feature_names()[i], reg.coef_[i])) for i in (-reg.coef_).argsort()[:10]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19846450703363194\n",
      "most negative\n",
      "('comes to my', -0.862983655346476)\n",
      "('its time to', -0.6081485241767967)\n",
      "('honestly think of', -0.5914928381833302)\n",
      "('look better without', -0.5688491724896164)\n",
      "('decided to post here', -0.5619540267589686)\n",
      "('and still have', -0.5619491599925692)\n",
      "('is the only', -0.5601745512441181)\n",
      "('the process of losing', -0.5588970398251094)\n",
      "('since last post', -0.5517987065304352)\n",
      "('pull any punches', -0.5385273167955745)\n",
      "most positive\n",
      "('what you would rate', 0.5969205165125211)\n",
      "('im wondering if its', 0.5895612279483424)\n",
      "('love to get some', 0.5420970766578329)\n",
      "('verification pic is', 0.5350903388825903)\n",
      "('me also do', 0.5332445811538595)\n",
      "('been going to the', 0.5323343926810438)\n",
      "('people say look like', 0.5247666120493227)\n",
      "('and im not sure', 0.5207030233194735)\n",
      "('version of myself', 0.5067437639397483)\n",
      "('see what others think', 0.4984005793340002)\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge().fit(X, y)\n",
    "print(ridge.score(X, y))\n",
    "\n",
    "print(\"most negative\")\n",
    "print(\"\\n\".join([str((vectorizer.get_feature_names()[i], ridge.coef_[i])) for i in ridge.coef_.argsort()[:10]]))\n",
    "print(\"most positive\")\n",
    "print(\"\\n\".join([str((vectorizer.get_feature_names()[i], ridge.coef_[i])) for i in (-ridge.coef_).argsort()[:10]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most negative\n",
      "('comes to my', -2.092183155986977)\n",
      "('its time to', -1.8917139205868054)\n",
      "('look better without', -1.8870581755046518)\n",
      "('comment on my appearance', -1.839073112718657)\n",
      "('honestly think of', -1.7752841341467007)\n",
      "('before want to', -1.6871411219661958)\n",
      "('pull any punches', -1.5673035223992189)\n",
      "('the process of losing', -1.5549577427998864)\n",
      "('to cut my hair', -1.5398031951730102)\n",
      "('since last post', -1.5371954196791227)\n",
      "most positive\n",
      "('and im not sure', 1.7767214630169692)\n",
      "('what you would rate', 1.7662444457886612)\n",
      "('im wondering if its', 1.7323504398018408)\n",
      "('verification pic is', 1.7182538252485915)\n",
      "('been going to the', 1.7097599059245445)\n",
      "('love to get some', 1.6220351769063548)\n",
      "('bad at taking', 1.6100155336814947)\n",
      "('me what you got', 1.5799349186148854)\n",
      "('me to do', 1.575397187114585)\n",
      "('me but be', 1.5512665662408673)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC()\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(\"most negative\")\n",
    "print(\"\\n\".join([str((vectorizer.get_feature_names()[i], clf.coef_[0][i])) for i in clf.coef_[0].argsort()[:10]]))\n",
    "print(\"most positive\")\n",
    "print(\"\\n\".join([str((vectorizer.get_feature_names()[i], clf.coef_[0][i])) for i in (-clf.coef_[0]).argsort()[:10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6911196911196911\n",
      "AUROC: 0.7629669266783874\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y, clf.predict(X)))\n",
    "print(\"AUROC:\", roc_auc_score(y, clf.decision_function(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = df[[\"title\", \"score\"]].dropna(subset=[\"score\"])\n",
    "X = scores.title\n",
    "X = X.apply(clean_title)\n",
    "y = ((scores.score - scores.score.mean()) / scores.score.std())\n",
    "y = y > 0\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=5, ngram_range=(3, 4))\n",
    "X = vectorizer.fit_transform(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC()\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(\"most negative\")\n",
    "print(\"\\n\".join([str((vectorizer.get_feature_names()[i], clf.coef_[0][i])) for i in clf.coef_[0].argsort()[:10]]))\n",
    "print(\"most positive\")\n",
    "print(\"\\n\".join([str((vectorizer.get_feature_names()[i], clf.coef_[0][i])) for i in (-clf.coef_[0]).argsort()[:10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/posts.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[20M] What do you think of the Arabic /Russian mix ☺️?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(clean_title(df.iloc[1].title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"0dcf00a5e4c24ffa8943c0bc7fa741da-0\" class=\"displacy\" width=\"1800\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">What</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">do</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">you</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">think</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Arabic</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Russian</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">mix</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">️</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">X</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0dcf00a5e4c24ffa8943c0bc7fa741da-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,89.5 570.0,89.5 570.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0dcf00a5e4c24ffa8943c0bc7fa741da-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0dcf00a5e4c24ffa8943c0bc7fa741da-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,177.0 565.0,177.0 565.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0dcf00a5e4c24ffa8943c0bc7fa741da-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0dcf00a5e4c24ffa8943c0bc7fa741da-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0dcf00a5e4c24ffa8943c0bc7fa741da-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0dcf00a5e4c24ffa8943c0bc7fa741da-0-3\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0dcf00a5e4c24ffa8943c0bc7fa741da-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M735.0,354.0 L743.0,342.0 727.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0dcf00a5e4c24ffa8943c0bc7fa741da-0-4\" stroke-width=\"2px\" d=\"M945,352.0 C945,89.5 1445.0,89.5 1445.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0dcf00a5e4c24ffa8943c0bc7fa741da-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0dcf00a5e4c24ffa8943c0bc7fa741da-0-5\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,177.0 1440.0,177.0 1440.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0dcf00a5e4c24ffa8943c0bc7fa741da-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0dcf00a5e4c24ffa8943c0bc7fa741da-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0dcf00a5e4c24ffa8943c0bc7fa741da-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0dcf00a5e4c24ffa8943c0bc7fa741da-0-7\" stroke-width=\"2px\" d=\"M770,352.0 C770,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0dcf00a5e4c24ffa8943c0bc7fa741da-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0dcf00a5e4c24ffa8943c0bc7fa741da-0-8\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,264.5 1610.0,264.5 1610.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0dcf00a5e4c24ffa8943c0bc7fa741da-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1610.0,354.0 L1618.0,342.0 1602.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do think', 'think', 'think of']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_fragments(text):\n",
    "    \"\"\"\n",
    "    Following the intuition that the\n",
    "    bulk of this functional information is contained in\n",
    "    the root of a question’s dependency parse along\n",
    "    with its outgoing arcs (Iyyer et al., 2014a), we\n",
    "    take the fragments of a question to be the root of\n",
    "    its parse tree, along with each (root, child) pair.\n",
    "    To capture cases when the operational word in\n",
    "    the question is not connected to its root (such as\n",
    "    “What...”), we also consider the initial unigram\n",
    "    and bigram of a question as fragments. The following\n",
    "    question has 5 fragments:\n",
    "        what, what is, going→*, is←going and going→do\n",
    "        \n",
    "        What is the minister going to do about ... ?\n",
    "    \"\"\"\n",
    "    doc = nlp(clean_title(text))\n",
    "    if len(doc) == 0:\n",
    "        return []\n",
    "    fragments = [str(doc[0]), str(doc[:2])]\n",
    "    # We take as NPs subtrees connected to the root with the\n",
    "    # following: nsubj, nsubjpass, dobj, iobj, pobj, attr.\n",
    "\n",
    "    np_deps = [\"nsubj\", \"nsubjpass\", \"dobj\", \"iobj\", \"pobj\", \"attr\"]\n",
    "    root = None\n",
    "    for tok in doc:\n",
    "\n",
    "        if tok.head.dep_ == \"ROOT\" and tok.dep_ not in np_deps:\n",
    "            if tok.dep_ == \"ROOT\":\n",
    "                root = tok\n",
    "                fragments.append(str(tok))\n",
    "                continue\n",
    "            if not root:\n",
    "                fragments.append(\"{} {}\".format(tok, tok.head))\n",
    "                continue\n",
    "            else:\n",
    "                fragments.append(\"{} {}\".format(tok.head, tok))\n",
    "                continue\n",
    "    return fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = df.title.apply(extract_fragments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "dh3ha2                                [How, Hows, How s, s]\n",
       "dh3b61           [What, What do, do think, think, think of]\n",
       "dh37sw    [Kinda, Kinda low, Kinda esteem, self esteem, ...\n",
       "dh368y    [Got, Got a, Got are, are, are with, are some,...\n",
       "dh32ch                             [RateMe, RateMe, RateMe]\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fragments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "frag_list = []\n",
    "for frags in fragments.to_numpy():\n",
    "    frag_list += frags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "frag_list = pd.Series(frag_list).str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rate me            8430\n",
       "be honest          3735\n",
       "just curious       2809\n",
       "looking for        2688\n",
       "please rate        1390\n",
       "rate please        1155\n",
       "please be          1146\n",
       "do think           1083\n",
       "rate and            911\n",
       "give me             892\n",
       "think do            889\n",
       "do look             739\n",
       "what do             693\n",
       "honest opinions     640\n",
       "just wondering      638\n",
       "let know            626\n",
       "rate my             603\n",
       "always been         594\n",
       "want know           577\n",
       "just want           555\n",
       "never had           521\n",
       "just got            514\n",
       "be please           511\n",
       "m curious           492\n",
       "how look            465\n",
       "just looking        465\n",
       "look do             460\n",
       "curious about       429\n",
       "curious think       428\n",
       "am i                424\n",
       "first time          416\n",
       "not sure            410\n",
       "how do              405\n",
       "rate honestly       396\n",
       "rate 110            380\n",
       "i have              374\n",
       "would like          356\n",
       "would love          334\n",
       "lost and            330\n",
       "been told           330\n",
       "’m curious          326\n",
       "know do             317\n",
       "would rate          296\n",
       "curious see         293\n",
       "never been          290\n",
       "be and              289\n",
       "do know             288\n",
       "like know           277\n",
       "curious to          270\n",
       "just turned         267\n",
       "dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frag_list[frag_list.apply(lambda x: len(x.split()) >= 2)].value_counts()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
